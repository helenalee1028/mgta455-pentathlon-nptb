---
title: "Helena2"
output: html_document
---
---
title: "Helena"
author: "Wenrui_Li"
date: "2/25/2019"
output: html_document
---

```{r r_setup, include = FALSE}
## initial settings
knitr::opts_chunk$set(
  comment = NA,
  echo = TRUE,
  error = TRUE,
  cache = FALSE,
  message = FALSE,
  dpi = 96,
  warning = FALSE
)

## width to use when printing tables etc.
options(
  width = 250,
  scipen = 100,
  max.print = 5000,
  stringsAsFactors = FALSE
)

## load radiant packages if neededi
if (!exists("r_environment")) library(radiant)
```

```{r}
## Loading the data from Dropbox/MGTA455-2019/data/
pentathlon_nptb <- readr::read_rds(file.path(radiant.data::find_dropbox(), "MGTA455-2019/data/pentathlon_nptb.rds"))
```

```{r}
library(tidyverse)
library(caret)
```


```{r}
train = pentathlon_nptb %>%
  filter(training == 1)
test = pentathlon_nptb %>%
  filter(training == 0)

## Get columns for gbm model
train_gbm = train[c("buyer","message","age", "gender", "income", "education", "children", "freq_endurance", "freq_strength", "freq_water", "freq_team", "freq_backcountry", "freq_winter", "freq_racquet")]
test_gbm = test[c("buyer","message","age", "gender", "income", "education", "children", "freq_endurance", "freq_strength", "freq_water", "freq_team", "freq_backcountry", "freq_winter", "freq_racquet")]
```

```{r}
cm <- function(dat, vars){
  
  cm_df <- as.data.frame(matrix(NA, ncol = 3, nrow = length(vars)))
  colnames(cm_df) <- c("var", "auc", "accuracy")
  
  for (i in 1:length(vars)){
    
    var <- vars[i]
    probs <- pull(dat, !!var)
    resp <- pull(dat, "buyer")
    
    predict <- ifelse(pull(dat, !!var) > 0.5, "TRUE", "FALSE") # predict whether a customer will buy 
    
    accuracy <- (sum(resp == "yes" & predict == "TRUE") + sum(resp == "no" & predict == "FALSE"))/nrow(dat)
    
    auc <- ModelMetrics::auc(ifelse(resp=="yes",1,0), probs)
    
    cm_vec <- c(var, auc, accuracy)
    cm_df[i,] <- cm_vec
  }
  return(cm_df)
}

```

Due to space limitaion, we didn't try shrinkage = 0.001 in the code, but it performs poorly according to ROC comparing to shrinkage = 0.1

```{r eval=FALSE}
# Using caret
caretGrid <- expand.grid(interaction.depth = c(2,4,6), 
                         n.trees = c(100,300),
                         shrinkage = c(0.1,0.01),
                         n.minobsinnode = c(20,40))
trainControl <- trainControl(method="cv", number=6, classProbs = TRUE, summaryFunction = twoClassSummary)
set.seed(123)
gbm_caret <- train(buyer ~ ., 
              data=train_gbm, 
              distribution="bernoulli", 
              method="gbm",
              trControl=trainControl, verbose=FALSE,
              tuneGrid=caretGrid, metric = "ROC")

print(gbm_caret)
gbm_caret$results
gbm_caret$bestTune

saveRDS(gbm_caret$bestTune, "gbm_best_tune_train1.rds")

saveRDS(gbm_caret$results, "gbm_tune_train1.rds")
```

```{r}
params1 <- readRDS("gbm_tune_train1.rds")
params1 %>% 
  arrange(desc(ROC))
best_tune1 <- readRDS("gbm_best_tune_train1.rds")
best_tune1
```

```{r eval=FALSE}
prediction1 <- predict(gbm_caret, newdata=test_gbm, type="prob", n.trees = 300)
test_gbm$p_gbm_caret = prediction$yes
```

Based on the performance in the previous trunk, tuning hyperparameters for the second time

```{r eval=FALSE}
caretGrid2 <- expand.grid(interaction.depth = c(2,4,6), 
                         n.trees = c(200,300,400),
                         shrinkage = 0.1,
                         n.minobsinnode = c(20,40))
trainControl2 <- trainControl(method="cv", number=6, classProbs = TRUE, summaryFunction = twoClassSummary)
set.seed(123)
gbm_caret2 <- train(buyer ~ ., 
              data=train_gbm, 
              distribution="bernoulli", 
              method="gbm",
              trControl=trainControl2, verbose=FALSE,
              tuneGrid=caretGrid2, metric = "ROC")

print(gbm_caret2)
gbm_caret2$results

saveRDS(gbm_caret2$results, "gbm_tune_train2.rds")
saveRDS(gbm_caret2$bestTune, "gbm_best_tune_train2.rds")
```

```{r}
params2 <- readRDS("gbm_tune_train2.rds")
params2 %>% 
  arrange(desc(ROC))
best_tune2 <- readRDS("gbm_best_tune_train2.rds")
```

```{r eval=FALSE}
prediction2 <- predict(gbm_caret2, newdata=test_gbm, type="prob", n.trees = 300)
test_gbm$p_gbm_caret2 = prediction2$yes
```

Based on the performance in the previous trunk, tuning hyperparameters for the third time

```{r eval=FALSE}
caretGrid3 <- expand.grid(interaction.depth = 6, 
                         n.trees = c(300,400),
                         shrinkage = c(0.12,0.1,0.08),
                         n.minobsinnode = c(20,30,40))
trainControl3 <- trainControl(method="cv", number=6, classProbs = TRUE, summaryFunction = twoClassSummary)
set.seed(123)
gbm_caret3 <- train(buyer ~ ., 
              data=train_gbm, 
              distribution="bernoulli", 
              method="gbm",
              trControl=trainControl3, verbose=FALSE,
              tuneGrid=caretGrid3, metric = "ROC")
#bag.fraction=0.75
print(gbm_caret3)
gbm_caret3$results

saveRDS(gbm_caret3$results, "gbm_tune_train3.rds")
saveRDS(gbm_caret3$bestTune, "gbm_best_tune_train3.rds")
```

```{r}
params3 <- readRDS("gbm_tune_train3.rds")
params3 %>% 
  arrange(desc(ROC))

best_tune3 <- readRDS("gbm_best_tune_train3.rds")
best_tune3
```

```{r eval=FALSE}
prediction3 <- predict(gbm_caret3, newdata=test_gbm, type="prob", n.trees = 400)
test_gbm$p_gbm_caret3 = prediction3$yes
```

Get the AUC score and accuracy of the previous three models

```{r eval=FALSE}
vals = c('p_gbm_caret','p_gbm_caret2','p_gbm_caret3')
cm(test_gbm,vals)
saveRDS(cm(test_gbm,vals), "gbm_tune_test_result.rds")
```

```{r}
readRDS("gbm_tune_test_result.rds")
best_tune3
```
As we can see, the model with the highest AUC score is the third optimal model with n.trees = 400, interaction.depth = 6, shrinkage = 0.08 and n.minobsinnode = 30